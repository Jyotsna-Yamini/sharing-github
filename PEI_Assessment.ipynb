{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245d7594-6ff6-47a5-b66f-c6a962b2bfa9",
   "metadata": {},
   "source": [
    "Verify the accuracy, completeness, and reliability of source data. Show your results in a SQL or Python output.\n",
    "\n",
    "-- The accuracy and completeness and reliability is decided based on the source, here excel, csv and json. Accuracy is decided by making sure we have all cell filled with valid data, no nulls, correct data form, no outliers. Completeness can be checked by checking for duplicates, continued primary key, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd3415e-9cb8-466e-b512-bdb3c6b0b7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "     ---------------------------------------- 11.1/11.1 MB 1.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python3.7\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting numpy>=1.22.4\n",
      "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     ---------------------------------------- 12.9/12.9 MB 1.4 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "     -------------------------------------- 509.2/509.2 KB 2.9 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "     -------------------------------------- 347.8/347.8 KB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\python3.7\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.6 pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Python3.7\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.5/96.5 KB 1.8 MB/s eta 0:00:00\n",
      "Installing collected packages: xlrd\n",
      "Successfully installed xlrd-2.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Python3.7\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ecb7c46-c1e4-4c3f-973b-df133c436420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer_ID    First     Last  Age Country\n",
      "0            1   Joseph     Rice   43     USA\n",
      "1            2     Gary    Moore   71     USA\n",
      "2            3     John   Walker   44      UK\n",
      "3            4     Eric   Carter   38      UK\n",
      "4            5  William  Jackson   58     UAE\n"
     ]
    }
   ],
   "source": [
    "#Fetching and reading Customer data  and creating dataframe for the same for python\n",
    "import pandas as pd\n",
    "path_customer = \"C:\\\\Users\\\\Asus\\\\Desktop\\\\PEI Assessment\\\\P_Assessment\\\\Customer.xls\"\n",
    "data_customer = pd.read_excel(path_customer, sheet_name='atkoe-u250m')\n",
    "df_customer = pd.DataFrame(data_customer)\n",
    "print(data_customer.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2f8cc-8b6c-40db-b139-60e2be2c1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching Customer data from db table using SQL\n",
    "Select * from Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d9a6ba8-9b6c-483e-95ba-8574983a017b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Customer_ID         Age\n",
      "count   250.000000  250.000000\n",
      "mean    125.500000   47.576000\n",
      "std      72.312977   18.978011\n",
      "min       1.000000   18.000000\n",
      "25%      63.250000   29.000000\n",
      "50%     125.500000   47.000000\n",
      "75%     187.750000   63.000000\n",
      "max     250.000000   80.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Customer_ID  250 non-null    int64 \n",
      " 1   First        250 non-null    object\n",
      " 2   Last         250 non-null    object\n",
      " 3   Age          250 non-null    int64 \n",
      " 4   Country      250 non-null    object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 9.9+ KB\n",
      "None\n",
      "Customer_ID    0\n",
      "First          0\n",
      "Last           0\n",
      "Age            0\n",
      "Country        0\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Validating data for Customer table using python\n",
    "print(data_customer.describe())\n",
    "print(data_customer.info())\n",
    "print(df_customer.isnull().sum())\n",
    "print(df_customer.duplicated().sum())\n",
    "\n",
    "#Looking at the data, there is no discrepancy like null object, age is within range that shows no outliers, and no duplicates but we need to check accuracy of each cell\n",
    "\n",
    "#Validating data for Customer table using SQL\n",
    "Select * \n",
    "From Customer\n",
    "where First IS NULL OR Last IS NULL OR Customer_ID IS NULL OR Age IS NULL\n",
    "\n",
    "Select Customer_ID, COUNT(*)\n",
    "From Customer\n",
    "Group By Customer_ID\n",
    "having count(*)>1\n",
    "\n",
    "#Since, I can't run these in any db, hence sharing the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57630025-a9e3-444e-bfd9-053b3df0ced4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Customer_ID     First     Last  Age Country\n",
      "0              1    Joseph     Rice   43     USA\n",
      "1              2      Gary    Moore   71     USA\n",
      "2              3      John   Walker   44      UK\n",
      "3              4      Eric   Carter   38      UK\n",
      "4              5   William  Jackson   58     UAE\n",
      "..           ...       ...      ...  ...     ...\n",
      "245          246    Justin  Stewart   73     USA\n",
      "246          247      John   Miller   53     USA\n",
      "247          248    Thomas  Hickman   23      UK\n",
      "248          249  Patricia   Garcia   19      UK\n",
      "249          250   Stephen    Jones   22     USA\n",
      "\n",
      "[238 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Checking for correct data format for each column\n",
    "letter_pattern = r'^[A-Za-z]+$'\n",
    "number_pattern = r'^[0-9]+$'\n",
    "\n",
    "first_valid = df_customer['First'].str.match(letter_pattern, na=False)\n",
    "last_valid = df_customer['Last'].str.match(letter_pattern, na=False)\n",
    "age_valid = df_customer['Age'].apply(lambda x:str(x).isdigit())\n",
    "country_valid = df_customer['Country'].str.match(letter_pattern, na=False)\n",
    "\n",
    "valid_mask = first_valid & last_valid & age_valid & country_valid\n",
    "\n",
    "valid_rows = df_customer.loc[valid_mask, ['Customer_ID', 'First', 'Last', 'Age', 'Country']]\n",
    "\n",
    "print(valid_rows)\n",
    "\n",
    "#Using SQL\n",
    "Select * \n",
    "From Customer\n",
    "where First REGEXP '^[A-Za-z]+$'\n",
    "AND Last REGEXP '^[A-Za-z]+$'\n",
    "AND isnumeric([Age])\n",
    "AND Country REGEXP '^[A-Za-z]+$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15163681-6791-4d06-89e5-50315cc02362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found\n"
     ]
    }
   ],
   "source": [
    "#There is a possibility that for same customer to have multiple ids, to avoid such situation we will confirm\n",
    "duplicates = valid_rows.groupby(['First', 'Last', 'Age', 'Country'])['Customer_ID'].nunique()\n",
    "duplicates = duplicates[duplicates>1]\n",
    "if not duplicates.empty:\n",
    "    print(f\"Duplicate combinations found:{duplicates}\")\n",
    "else:\n",
    "    print(\"No duplicates found\")\n",
    "\n",
    "#Using SQL\n",
    "Select first, last, age, country, count(Customer_ID) as ID\n",
    "from Customer\n",
    "group by first, last, age, country\n",
    "having ID > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea11c0df-463d-4788-82d1-520e5cab1f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 238 entries, 0 to 249\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Customer_ID  238 non-null    int64 \n",
      " 1   First        238 non-null    object\n",
      " 2   Last         238 non-null    object\n",
      " 3   Age          238 non-null    int64 \n",
      " 4   Country      238 non-null    object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#To keep consistancy\n",
    "df_customer = valid_rows\n",
    "print(df_customer.info())\n",
    "\n",
    "# the data validation has removed 12 rows with inconsistent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "731cb142-2b45-453d-951c-635bfa20fed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Order_ID       Amount  Customer_ID\n",
      "count  250.000000    250.00000   250.000000\n",
      "mean   125.500000   2130.00000   130.404000\n",
      "std     72.312977   3575.43493    69.192711\n",
      "min      1.000000    200.00000     4.000000\n",
      "25%     63.250000    300.00000    71.500000\n",
      "50%    125.500000    400.00000   125.500000\n",
      "75%    187.750000   1500.00000   190.750000\n",
      "max    250.000000  12000.00000   250.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Order_ID     250 non-null    int64 \n",
      " 1   Item         250 non-null    object\n",
      " 2   Amount       250 non-null    int64 \n",
      " 3   Customer_ID  250 non-null    int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 7.9+ KB\n",
      "None\n",
      "Order_ID       0\n",
      "Item           0\n",
      "Amount         0\n",
      "Customer_ID    0\n",
      "dtype: int64\n",
      "0\n",
      "   Order_ID      Item  Amount  Customer_ID\n",
      "0         1  Keyboard     400          139\n",
      "1         2     Mouse     300          250\n",
      "2         3   Monitor   12000          239\n",
      "3         4  Keyboard     400          153\n",
      "4         5  Mousepad     250          153\n"
     ]
    }
   ],
   "source": [
    "#Validating data for Order Table using python\n",
    "path_order = \"C:\\\\Users\\\\Asus\\\\Desktop\\\\PEI Assessment\\\\P_Assessment\\\\Order.csv\"\n",
    "data_order = pd.read_csv(path_order)\n",
    "df_order = pd.DataFrame(data_order)\n",
    "print(data_order.describe()) \n",
    "print(data_order.info())  \n",
    "print(df_order.isnull().sum())  -- non-null data for all columns\n",
    "print(df_order.duplicated().sum()) -- no duplicates\n",
    "print(df_order.head(5))\n",
    "\n",
    "#Validating Using SQL\n",
    "Select * \n",
    "from Order\n",
    "where Order_ID IS NULL OR Item IS NULL OR Amount IS NULL OR Customer_ID IS NULL\n",
    "\n",
    "Select Order_ID, Count(*)\n",
    "from Order\n",
    "group by Order_ID\n",
    "having count(*)>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c41831cc-d07b-4041-8098-dfdd9ea422d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since Order should only be placed for valid customers, that is customers that are already present in Customer table,usually this is taken care during \n",
    "#data modelling to make sure Order table is created using reference from Customer table \n",
    "\n",
    "Create table Order(\n",
    "    Item Varchar(100),\n",
    "    Order_ID INT,\n",
    "    Constraint Customer_id\n",
    "      Foreign key (Customer_id)\n",
    "      References Customer(Customer_id)\n",
    "      On delete cascade\n",
    ")\n",
    "\n",
    "#Still we can check if the customers present in Order table is already existing in Customer table or not\n",
    "\n",
    "Select o.customer_id\n",
    "from Order o\n",
    "where o.customer_id not in (Select customer_id from Customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0d0ce8c-642e-4e81-b360-412899619bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Order_ID      Item  Amount  Customer_ID\n",
      "0         1  Keyboard     400          139\n",
      "1         2     Mouse     300          250\n",
      "2         3   Monitor   12000          239\n",
      "3         4  Keyboard     400          153\n",
      "4         5  Mousepad     250          153\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 238 entries, 0 to 249\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Order_ID     238 non-null    int64 \n",
      " 1   Item         238 non-null    object\n",
      " 2   Amount       238 non-null    int64 \n",
      " 3   Customer_ID  238 non-null    int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 9.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Validating the same use case using python\n",
    "valid_order_with_existing_customers = df_order[df_order['Customer_ID'].isin(df_customer['Customer_ID'])]\n",
    "print(valid_order_with_existing_customers.head(5))\n",
    "print(valid_order_with_existing_customers.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "112b5cc5-9377-4f40-93c8-3dcf3cb1df2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Order_ID     250 non-null    int64 \n",
      " 1   Item         250 non-null    object\n",
      " 2   Amount       250 non-null    int64 \n",
      " 3   Customer_ID  250 non-null    int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 7.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_order.info())\n",
    "#this shows that there were orders created from wrong/dummy/incorrect customer details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27a250c9-522c-4370-94d9-c11f73892827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Order_ID      Item  Amount  Customer_ID\n",
      "20         21  Keyboard     400          171\n",
      "60         61  Keyboard     400          118\n",
      "64         65  Mousepad     250          198\n",
      "77         78  Mousepad     200          211\n",
      "102       103   Monitor   12000          242\n",
      "168       169   DDR RAM    1500          236\n",
      "169       170   Headset     900          214\n",
      "200       201  Keyboard     400          109\n",
      "212       213   Monitor   12000          118\n",
      "220       221  Keyboard     400          198\n",
      "224       225  Mousepad     250          113\n",
      "230       231  Keyboard     400          162\n"
     ]
    }
   ],
   "source": [
    "#We can check the unmatched values like this\n",
    "import pandas as pd\n",
    "\n",
    "merged_df = pd.merge(df_order, df_customer, on='Customer_ID', how='left', indicator=True)\n",
    "unmatched_orders = merged_df[merged_df['_merge'] =='left_only']\n",
    "unmatched_orders = unmatched_orders[df_order.columns]\n",
    "print(unmatched_orders)\n",
    "\n",
    "#SQL\n",
    "Select o.*\n",
    "from Order o\n",
    "left join Customer c on c.customer_id = o.customer_id\n",
    "where c.customer_id IS NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24ba045b-6ce3-4627-b6b9-293bad941bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 238 entries, 0 to 237\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Order_ID     238 non-null    int64 \n",
      " 1   Item         238 non-null    object\n",
      " 2   Amount       238 non-null    int64 \n",
      " 3   Customer_ID  238 non-null    int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 7.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Cleaning the actual table\n",
    "valid_orders = pd.merge(df_order, df_customer, on='Customer_ID', how='inner')\n",
    "valid_orders_only = valid_orders[df_order.columns]\n",
    "print(valid_orders_only.info())\n",
    "\n",
    "df_order=valid_orders_only\n",
    "\n",
    "#Using SQL\n",
    "\n",
    "Select o.*\n",
    "from Order o\n",
    "inner join Customer c on o.customer_id = c.customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0a71e2a-5e19-468d-8161-9e0197d1965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Shipping_ID  Customer_ID\n",
      "count   250.000000   250.000000\n",
      "mean    125.500000   120.620000\n",
      "std      72.312977    73.893848\n",
      "min       1.000000     1.000000\n",
      "25%      63.250000    53.250000\n",
      "50%     125.500000   118.000000\n",
      "75%     187.750000   187.500000\n",
      "max     250.000000   248.000000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Shipping_ID  250 non-null    int64 \n",
      " 1   Status       250 non-null    object\n",
      " 2   Customer_ID  250 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n",
      "Shipping_ID    0\n",
      "Status         0\n",
      "Customer_ID    0\n",
      "dtype: int64\n",
      "0\n",
      "   Shipping_ID     Status  Customer_ID\n",
      "0            1    Pending          173\n",
      "1            2    Pending          155\n",
      "2            3  Delivered          242\n",
      "3            4    Pending          223\n",
      "4            5  Delivered           72\n"
     ]
    }
   ],
   "source": [
    "#Cleaning Shipping table the same way\n",
    "path_shipping = \"C:\\\\Users\\\\Asus\\\\Desktop\\\\PEI Assessment\\\\P_Assessment\\\\Shipping.json\"\n",
    "data_shipping = pd.read_json(path_shipping)\n",
    "df_shipping = pd.DataFrame(data_shipping)\n",
    "print(data_shipping.describe()) \n",
    "print(data_shipping.info())  \n",
    "print(df_shipping.isnull().sum())  -- no nulls\n",
    "print(df_shipping.duplicated().sum()) -- no duplicates\n",
    "print(data_shipping.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e02377b6-e752-4ba6-8956-86b540832126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Shipping_ID     Status  Customer_ID\n",
      "3             4    Pending          223\n",
      "5             6    Pending           29\n",
      "7             8  Delivered          193\n",
      "9            10  Delivered           17\n",
      "10           11    Pending          157\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 139 entries, 3 to 248\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Shipping_ID  139 non-null    int64 \n",
      " 1   Status       139 non-null    object\n",
      " 2   Customer_ID  139 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 4.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Only those orders should have customer details who are already present in order table\n",
    "valid_shipping_with_existing_customer = df_shipping[df_shipping['Customer_ID'].isin(df_order['Customer_ID'])]\n",
    "print(valid_shipping_with_existing_customer.head(5))\n",
    "print(valid_shipping_with_existing_customer.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "533999c3-8712-45b9-ae23-191c6ba5a9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 218 entries, 0 to 217\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Shipping_ID  218 non-null    int64 \n",
      " 1   Status       218 non-null    object\n",
      " 2   Customer_ID  218 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 5.2+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 250 entries, 0 to 249\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Shipping_ID  250 non-null    int64 \n",
      " 1   Status       250 non-null    object\n",
      " 2   Customer_ID  250 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "valid_shipping = pd.merge(df_shipping, df_order, on='Customer_ID', how='inner')\n",
    "valid_shipping_only = valid_shipping[df_shipping.columns]\n",
    "print(valid_shipping_only.info())\n",
    "print(df_shipping.info())\n",
    "\n",
    "df_shipping = valid_shipping_only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2efceb-33f5-493d-a7bd-6ed80d4158ab",
   "metadata": {},
   "source": [
    "For accuracy and validation i did \n",
    "1. Duplication check\n",
    "2. Data Format check\n",
    "3. non null check\n",
    "4. Data continuation check\n",
    "5. Dependency check\n",
    "6. Regex check\n",
    "7. Outlier check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8103432-cada-4b44-86dc-b54a06784066",
   "metadata": {},
   "source": [
    "Based on your findings, define and outline the requirements for anticipated datasets, detailing the proposed domain model to support the reporting requirements noted below. \n",
    "Based on the dataset and questions and with the first look this looks like Sales data with product and shipping. With the same case in mind the datasets requirement would be\n",
    "1. Customer Dimension Table - same as it is, couple of columns can be added based on requirement like gender and if we are planning SCD mainatinance then is_active, joining_date, releasing_date and so on\n",
    "2. Product Dimension Table - Product_id, product_name\n",
    "3. Orders (Fact Table)\n",
    "4. Date - for better hierarchial queries and filters\n",
    "\n",
    "Proposed Domain Model\n",
    "While working on staging area for processing, cleaning, and validating, snowflake schema with dimension normalized helps is cleaner data which in later stages can go as it is, if \n",
    "1. the same data also brings in sub-categories or the granularity is low that is aggregated, so let's say monthly sales or so\n",
    "2. multi layer drill down is needed like categories,sub-categories, product or region, market, country\n",
    "3. if dimension table changes a lot, in this case customer data update or in general region market update,\n",
    "snowflake schema is a better option as it handles normalized dimension.\n",
    "\n",
    "Meanwhile, I'll go with star schema if\n",
    "1. high-granularity or flat dimension to reduce complexity is needed\n",
    "2. No frequent changes\n",
    "3. Faster queries due to lower joins - best for reporting\n",
    "\n",
    "All the dimension table mapped to fact table using one id as one to many relationship between fact and dimension table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36216b5a-d4f8-4c9f-ba36-c73ba0442bc4",
   "metadata": {},
   "source": [
    "Prepare a story with technical specifications for one part of the data model for a data engineer to include technical specifications and transformations. This story should give enough information for a Data Engineer to build table(s) and for a QA engineer to test it. \n",
    "\n",
    "Looking at the sales data, some common questions that I would like to answer few question like sales per month per country, or product sales review, or country sales pattern, or product sales pattern throughout the year, or YoY comparisons.\n",
    "\n",
    "To answer these questions we can have a target table with either processed raw data that is needed to create a query for all these scenarios or we can have stored procedure saved to create tables for let's say montly sales per country,per product, per customer.\n",
    "\n",
    "Let's look at both the solutions:\n",
    "I want dimension tables like\n",
    "1. Customer Dimension table with customer details where customer id is the primary key and everything is non null field, with no duplicates\n",
    "2. Product Dimension table with item details like item id, item name, price where item id is primary key and every field is non null field with no duplicates\n",
    "3. Country Dimension table with country id and name where country id is non null field with no duplicates\n",
    "4. Date Dimension table that stores full date, month, year, date, month-year key, quarter, day of week\n",
    "\n",
    "to Achieve Target table from which we can execute queries based on filters and conditions:\n",
    "1. Fact Table with fields from raw data (customer_id (constraint reference with customer dimension table), item_id (constraint regerence with product table), country_id (constraint reference with country table), sale date, quantity, status, last_updated (to have ETL update timestamp)) - This provides a generic table to perform queries.\n",
    "2. Scenario Specific Table like sales summary monthly which should be created on 5th of every month,\n",
    "   a. must have sale date between first and last day of previous month,\n",
    "   b. status must be completed,\n",
    "   c. join with customer dim, product dim, country dim, date dim with complete date\n",
    "   d. group by customer id, item id, country id, sale month\n",
    "   e. aggregate calculation sum(quantity), sum(amount) based on item id and quantity\n",
    "   f. table created date - for auditing\n",
    "\n",
    "\n",
    "QA Validation \n",
    "QA can test the scenario by\n",
    "1. Date filtering - Only records from last calendar month included\n",
    "2. Record Count - Matches the records from source\n",
    "3. No nulls in Customer, Item or Country\n",
    "4. No Duplicates\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4286de4c-1410-4d5c-9b03-1c5575c97eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the total amount spent and the country for the Pending delivery status for each country.\n",
    "Select c.country, sum(amount) as total\n",
    "from Customer s\n",
    "join Order o\n",
    "on c.customer_id = 0.customer_id\n",
    "join Shipping s\n",
    "on c.customer_id = s.customer_id\n",
    "where status='Pending'\n",
    "group by c.country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956a8d5-5906-42ef-88a3-bc946f2fafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the total number of transactions, total quantity sold, and total amount spent for each customer, along with the product details.\n",
    "\n",
    "Select count(order_id) as total_order, count(item) as total_item, sum(amount) as total_amount, customer_id, item\n",
    "from Order\n",
    "group by customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e241eb8b-d982-4aa2-997b-028b57404ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the maximum product purchased for each country.\n",
    "#1. the maximum number of item purchased for each country\n",
    "SELECT country, item, total_purchases\n",
    "FROM (\n",
    "    SELECT \n",
    "        c.country,\n",
    "        o.item,\n",
    "        COUNT(*) AS total_purchases,\n",
    "        RANK() OVER (PARTITION BY c.country ORDER BY COUNT(*) DESC) AS rnk\n",
    "    FROM orders o\n",
    "    JOIN customers c ON o.customer_id = c.customer_id\n",
    "    GROUP BY c.country, o.item\n",
    ") ranked_items\n",
    "WHERE rnk = 1;\n",
    "\n",
    "#2. the maximum amount per country\n",
    "SELECT country, item, total_amount\n",
    "FROM (\n",
    "    SELECT \n",
    "        c.country,\n",
    "        o.item,\n",
    "        SUM(o.amount) AS total_amount,\n",
    "        RANK() OVER (PARTITION BY c.country ORDER BY SUM(o.amount) DESC) AS rnk\n",
    "    FROM orders o\n",
    "    JOIN customers c ON o.customer_id = c.customer_id\n",
    "    GROUP BY c.country, o.item\n",
    ") ranked_items\n",
    "WHERE rnk = 1;\n",
    "\n",
    "#3. the maximum items per country irrespective of each item\n",
    "SELECT country, item, total_purchases\n",
    "FROM (\n",
    "    SELECT \n",
    "        c.country,\n",
    "        o.item,\n",
    "        COUNT(*) AS total_purchases,\n",
    "        RANK() OVER (PARTITION BY c.country ORDER BY COUNT(*) DESC) AS rnk\n",
    "    FROM orders o\n",
    "    JOIN customers c ON o.customer_id = c.customer_id\n",
    "    GROUP BY c.country, o.item\n",
    ") ranked_items\n",
    "WHERE rnk = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a510280-af18-4e26-9ed0-32d73bbebd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the most purchased product based on the age category less than 30 and above 30.\n",
    "\n",
    "Select item, \n",
    "SUM(CASE when c.age < 30 then 1 else 0 end) as below_30,\n",
    "SUM(CASE when c.age > 30 then 1 else 0 end) as above_30\n",
    "from Order o\n",
    "Join Customer c on c.customer_id = o.customer_id\n",
    "group by item\n",
    "limit 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a188093a-e4c8-4dd2-b2ce-d5ab5d7ae07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the country that had minimum transactions and sales amount.\n",
    "With item_count as (\n",
    "Select c.country, o.Item, Count(*) as total_product,\n",
    "                                Row_number() OVER (PARTITION BY c.Country ORDER BY COUNT(*) DESC)as rn,\n",
    "                                SUM(amount) OVER (PARTITION BY c.Country ORDER BY SUM(amount) ASC) AS amount\n",
    "                                from Customer c\n",
    "                                Join Order o on c.cutomer_id = o.customer_id\n",
    "                                Group by c.country, o.Item\n",
    "                                                  )\n",
    "Select Country, Item, total_product, amount from item_count limit 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
